{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Welcome to Mellea (Docs: Welcome, Quickstart)\n",
                "\n",
                "Welcome to the interactive demo for **Mellea**, a library for writing generative programs. \n",
                "In this notebook, we will explore how Mellea allows you to write programs that generate content, validate it against requirements, and repair it if necessary.\n",
                "\n",
                "**Docs Reference:** [Welcome](https://docs.mellea.ai/overview/mellea-welcome), [Quickstart](https://docs.mellea.ai/overview/quick-start)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Initializing Mellea Session...\n",
                        "Session started! Model: granite4:micro\n"
                    ]
                }
            ],
            "source": [
                "import mellea\n",
                "from mellea.backends import ModelOption\n",
                "from mellea.backends.ollama import OllamaModelBackend\n",
                "\n",
                "# Initialize Mellea with the local Ollama backend and Granite model\n",
                "print(\"Initializing Mellea Session...\")\n",
                "m = mellea.MelleaSession(\n",
                "    backend=OllamaModelBackend(\n",
                "        model_id=\"granite4:micro\", \n",
                "        model_options={ModelOption.SEED: 42} # Fixed seed for reproducibility\n",
                "    )\n",
                ")\n",
                "print(\"Session started! Model: granite4:micro\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Your First Instruction\n",
                "\n",
                "The core of Mellea is the `instruct` method. You give it a natural language instruction, and it returns a generated result.\n",
                "Let's start with something simple."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/2 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;20m=== 16:34:05-INFO ======\n",
                        "SUCCESS\u001b[0m\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/2 [00:06<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Code in Python flows,\n",
                        "Elegance meets simplicity.\n",
                        "Logic takes its stage.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "response = m.instruct(\"Write a short haiku about writing python code.\")\n",
                "print(response)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# The Loop: Instruct-Validate-Repair (Docs: Requirements)\n",
                "\n",
                "Generative models can be unpredictable. Mellea's power lies in its **Instruct-Validate-Repair** loop. \n",
                "You can define **Requirements** (`req`) and **Checks** (`check`) that the output *must* satisfy. If the model fails, Mellea uses a **Strategy** to try again or fix it.\n",
                "\n",
                "**Docs Reference:** [Requirements](https://docs.mellea.ai/overview/requirements)\n",
                "\n",
                "### Example: Generating a Helper Email with Constraints\n",
                "We want to generate an email that:\n",
                "1.  Has a salutation.\n",
                "2.  Does **not** use the word 'regards'.\n",
                "3.  (Optional strict check) Uses only lower-case letters (just to show validation failure and repair)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Generating email for Arush...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/5 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;20m=== 16:34:11-INFO ======\n",
                        "SUCCESS\u001b[0m\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/5 [00:05<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Success! Email generated:\n",
                        "Subject: Heartfelt Thanks for Your Contribution\n",
                        "\n",
                        "Dear Arush,\n",
                        "\n",
                        "I hope this message finds you well. I am writing to express my sincere gratitude for your invaluable contribution towards our recent team project.\n",
                        "\n",
                        "Your dedication, creativity and commitment did not go unnoticed, and they played an instrumental role in achieving the successful outcome of the project. The quality of work produced was truly impressive and a testament to your skills and abilities.\n",
                        "\n",
                        "Please allow me to reiterate how much we appreciate your hard work and all that you have contributed. Your efforts have been crucial in making this project a success.\n",
                        "\n",
                        "Thank you once again for everything.\n",
                        "\n",
                        "Best regards,\n",
                        "\n",
                        "[Your Name]\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "from mellea.stdlib.requirements import req, check, simple_validate\n",
                "from mellea.stdlib.sampling import RejectionSamplingStrategy\n",
                "\n",
                "# Define requirements\n",
                "requirements = [\n",
                "    req(\"The email should have a salutation\"),\n",
                "    check(\"The email should not mention the word 'regards'\"),\n",
                "    # req(\"Use only lower-case letters\", validation_fn=simple_validate(lambda s: s.islower())) # Uncomment to test strict validation failure\n",
                "]\n",
                "\n",
                "def write_email(name, notes):\n",
                "    print(f\"Generating email for {name}...\")\n",
                "    email_candidate = m.instruct(\n",
                "        \"Write an email to {{name}} using the notes following: {{notes}}.\",\n",
                "        requirements=requirements,\n",
                "        # RejectionSamplingStrategy tries up to 'loop_budget' times to get a result that passes requirements\n",
                "        strategy=RejectionSamplingStrategy(loop_budget=5),\n",
                "        user_variables={\"name\": name, \"notes\": notes},\n",
                "        return_sampling_results=True,\n",
                "    )\n",
                "    \n",
                "    if email_candidate.success:\n",
                "        print(\"\\nSuccess! Email generated:\")\n",
                "        return str(email_candidate.result)\n",
                "    else:\n",
                "        print(\"\\nFailed to meet requirements.\")\n",
                "        return email_candidate.sampling_results[0].value\n",
                "\n",
                "# Test it\n",
                "print(write_email(\"Arush\", \"Thanks for helping with the team project.\"))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Advanced: Core Concepts & Generative Programming\n",
                "\n",
                "**Docs Reference:** [Generative Programming](https://docs.mellea.ai/overview/project-mellea), [Core Concepts](https://docs.mellea.ai/core-concept/generative-slots)\n",
                "\n",
                "In this section, we touch on more advanced concepts. Mellea treats prompts not just as strings, but as programs with **Slots**, **Context**, and **Agents**.\n",
                "\n",
                "### Variable Injection (Context)\n",
                "You saw `user_variables` above. This is part of Mellea's Context Management system, allowing you to inject data safely into prompts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/2 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;20m=== 16:34:11-INFO ======\n",
                        "SUCCESS\u001b[0m\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/2 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Hello in Spanish: The translation of \"Hello\" in Spanish is \"Hola\".\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Quick example of dynamic variables\n",
                "response = m.instruct(\n",
                "    \"Translate the following word to Spanish: {{word}}\",\n",
                "    user_variables={\"word\": \"Hello\"}\n",
                ")\n",
                "print(f\"Hello in Spanish: {response}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/2 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;20m=== 16:34:18-INFO ======\n",
                        "SUCCESS\u001b[0m\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/2 [00:06<?, ?it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sure! Imagine you have a big box of toys. Now, when you want to play with your favorite toy car, in the regular games or world (which we can call 'classical computing'), it's like saying \"Okay, let's only look for this car right now\". You don't find other cars, you just search one by one until you find it.\n",
                        "\n",
                        "Now, quantum computing is more like having a magic box of toys. In this magical box, your toy car and all the other cars can be in many places at once! It's kind of like your car being both here and there at the same time. This makes it much faster to find what you want because everything isn't stuck just in one place.\n",
                        "\n",
                        "So, quantum computing is a bit different from our regular games or world - it's more magical and can do things really fast that we can't do otherwise!\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "# Enter your instruction below\n",
                "my_instruction = \"Explain quantum computing to a 5 year old.\"\n",
                "\n",
                "result = m.instruct(my_instruction)\n",
                "print(result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generative Slots\n",
                "\n",
                "``GenerativeSlot`` is a function whose implementation is provieded by an LLM.In Mellea you define these using ``@generative`` decorator\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;20m=== 17:13:13-INFO ======\n",
                        "Starting Mellea session: backend=ollama, model=granite4:micro, context=SimpleContext\u001b[0m\n",
                        "positive\n"
                    ]
                }
            ],
            "source": [
                "from typing import Literal\n",
                "from mellea import generative, start_session\n",
                "\n",
                "\n",
                "@generative\n",
                "def classify_sentiment(text: str) -> Literal[\"positive\", \"negative\", \"neutral\"]:\n",
                "    \"\"\"Classify the sentiment of the input text as 'positive', 'negative', or 'neutral'.\"\"\"\n",
                "    ...\n",
                " \n",
                "m = start_session()\n",
                "sentiment = classify_sentiment(m, text = \"I love this product!\")\n",
                "print(sentiment)\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[38;20m=== 17:26:23-INFO ======\n",
                        "Starting Mellea session: backend=ollama, model=granite4:micro, context=ChatContext, model_options={'@@@max_new_tokens@@@': 10}\u001b[0m\n",
                        "grade =  5\n"
                    ]
                }
            ],
            "source": [
                "# from mellea.std.base import ChatContext is old \n",
                "from mellea.stdlib.context import ChatContext\n",
                "from mellea import start_session\n",
                "from mellea.backends import ModelOption\n",
                "from mellea import generative   \n",
                "\n",
                "# ChatContext is used to maintain conversation history across multiple model calls. \n",
                "# Unlike SimpleContext (the default), which resets the chat history on each call, \n",
                "# ChatContext behaves like a chat history where previous messages are remembered.\n",
                "\n",
                "@generative\n",
                "def grade_syntax(code: str) -> int:\n",
                "    \"\"\" Grade the code based on correct implementation of the function\n",
                "    args:\n",
                "        code: str (to be graded)\n",
                "    returns:\n",
                "        int : a grade between 1(worst) and 10(best)\n",
                "    \"\"\"\n",
                "codes = (\n",
                "    \" def add(a, b):\\n    return a + b\",\n",
                "    \"def subtract(a,b): cout<<a-b<<endl\",\n",
                "    \"int multiply(int a,int b) { return a*b}\"\n",
                ")\n",
                "m = start_session(ctx = ChatContext() , model_options = {ModelOption.MAX_NEW_TOKENS: 10})\n",
                "for code in codes :\n",
                "    grade = grade_syntax(m, code = code)\n",
                "    print(\"grade = \",grade)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python (Mellea Project)",
            "language": "python",
            "name": "mellea_project"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
